name: Build-GeoSite-Dat

on:
  workflow_dispatch: # –¢–æ–ª—å–∫–æ —Ä—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.24'

      - name: Check for changes in geosite data
        id: check_changes
        run: |
          echo "Checking geosite data files..."
          mkdir -p geosite.dat/data
          
          # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –≤—Å–µ–≥–¥–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º, –µ—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –≤—Ä—É—á–Ω—É—é
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "Manual run detected, will generate geosite.dat"
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Validate GeoSite Files
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          echo "Validating geosite data files..."
          cd geosite.dat/data
          
          ERROR_COUNT=0
          FILE_COUNT=0
          
          for file in *; do
            if [ -f "$file" ] && [ ! -d "$file" ]; then
              FILE_COUNT=$((FILE_COUNT + 1))
              echo "üìÑ Found: $file"
              
              if [ ! -s "$file" ]; then
                echo "‚ùå ERROR: $file is empty"
                ERROR_COUNT=$((ERROR_COUNT + 1))
                continue
              fi
              
              FIRST_LINE=$(head -1 "$file" | xargs)
              if [[ ! "$FIRST_LINE" =~ ^[a-zA-Z0-9_-]+:$ ]]; then
                echo "‚ùå ERROR: First line must be 'category-name:'"
                echo "  Found: '$FIRST_LINE'"
                ERROR_COUNT=$((ERROR_COUNT + 1))
              else
                echo "  ‚úÖ Category: ${FIRST_LINE%:}"
              fi
            fi
          done
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "‚ùå ERROR: No files found in geosite.dat/data/"
            exit 1
          fi
          
          if [ $ERROR_COUNT -gt 0 ]; then
            echo "‚ùå Validation failed with $ERROR_COUNT error(s)"
            exit 1
          fi
          
          echo "‚úÖ Found $FILE_COUNT valid geosite files"

      - name: Create GeoSite Generator Script
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          cat << 'EOF' > generate_geosite.go
          package main
          
          import (
          	"bufio"
          	"encoding/binary"
          	"fmt"
          	"log"
          	"os"
          	"path/filepath"
          	"sort"
          	"strings"
          )
          
          type Site struct {
          	Type  string
          	Value string
          	Attrs []string
          }
          
          func writeVarint(v uint32) []byte {
          	var buf [binary.MaxVarintLen32]byte
          	n := binary.PutUvarint(buf[:], uint64(v))
          	return buf[:n]
          }
          
          func encodeField(num int, wireType int, data []byte) []byte {
          	tag := uint32((num << 3) | wireType)
          	res := writeVarint(tag)
          	if wireType == 2 {
          		res = append(res, writeVarint(uint32(len(data)))...)
          	}
          	res = append(res, data...)
          	return res
          }
          
          func parseLine(line string, lineNum int) (string, *Site) {
          	line = strings.TrimSpace(line)
          	if line == "" || strings.HasPrefix(line, "#") {
          		return "", nil
          	}
          	
          	if lineNum == 0 && strings.HasSuffix(line, ":") {
          		return line, nil
          	}
          	
          	parts := strings.SplitN(line, " ", 2)
          	pattern := parts[0]
          	var attrs []string
          	
          	if len(parts) > 1 {
          		attrStr := parts[1]
          		attrParts := strings.Split(attrStr, " ")
          		for _, attr := range attrParts {
          			attr = strings.TrimSpace(attr)
          			if attr != "" && strings.HasPrefix(attr, "@") {
          				attrs = append(attrs, strings.TrimPrefix(attr, "@"))
          			}
          		}
          	}
          	
          	var patternType, patternValue string
           
          	switch {
          	case strings.HasPrefix(pattern, "domain:"):
          		patternType = "domain"
          		patternValue = strings.TrimPrefix(pattern, "domain:")
          	case strings.HasPrefix(pattern, "regexp:"):
          		patternType = "regexp"
          		patternValue = strings.TrimPrefix(pattern, "regexp:")
          	case strings.HasPrefix(pattern, "full:"):
          		patternType = "full"
          		patternValue = strings.TrimPrefix(pattern, "full:")
          	case strings.HasPrefix(pattern, "keyword:"):
          		patternType = "keyword"
          		patternValue = strings.TrimPrefix(pattern, "keyword:")
          	case pattern == "@":
          		patternType = "reference"
          		patternValue = "@"
          	case strings.HasPrefix(pattern, "@"):
          		patternType = "reference"
          		patternValue = strings.TrimPrefix(pattern, "@")
          	default:
          		patternType = "domain"
          		patternValue = pattern
          	}
          	
          	return pattern, &Site{
          		Type:  patternType,
          		Value: patternValue,
          		Attrs: attrs,
          	}
          }
          
          func encodeSite(site *Site) []byte {
          	var data []byte
          	data = append(data, encodeField(1, 2, []byte(site.Type))...)
          	data = append(data, encodeField(2, 2, []byte(site.Value))...)
          	for _, attr := range site.Attrs {
          		data = append(data, encodeField(3, 2, []byte(attr))...)
          	}
          	return data
          }
          
          func main() {
          	dataDir := "geosite.dat/data"
          	outputFile := "geosite.dat"
           
          	entries, err := os.ReadDir(dataDir)
          	if err != nil {
          		log.Fatalf("Failed to read data directory: %v", err)
          	}
          	
          	var allEntries []byte
          	typeStats := make(map[string]int)
          	totalSites := 0
           
          	for _, entry := range entries {
          		if entry.IsDir() || strings.HasPrefix(entry.Name(), ".") {
          			continue
          		}
           
          		categoryName := entry.Name()
          		fmt.Printf("üìÅ Processing: %s\n", categoryName)
           
          		filePath := filepath.Join(dataDir, entry.Name())
          		file, err := os.Open(filePath)
          		if err != nil {
          			log.Printf("Warning: Failed to open %s: %v", filePath, err)
          			continue
          		}
           
          		var sites []*Site
          		scanner := bufio.NewScanner(file)
          		lineNum := 0
           
          		for scanner.Scan() {
          			pattern, site := parseLine(scanner.Text(), lineNum)
          			lineNum++
                  if site != nil && pattern != "" {
                    sites = append(sites, site)
                    typeStats[site.Type]++
                  }
          		}
           
          		file.Close()
           
          		if err := scanner.Err(); err != nil {
          			log.Printf("Warning: Error reading %s: %v", filePath, err)
          		}
           
          		sort.Slice(sites, func(i, j int) bool {
          			if sites[i].Type != sites[j].Type {
          				return sites[i].Type < sites[j].Type
          			}
          			return sites[i].Value < sites[j].Value
          		})
           
          		var geoData []byte
          		geoData = append(geoData, encodeField(1, 2, []byte(categoryName))...)
           
          		for _, site := range sites {
          			siteData := encodeSite(site)
          			geoData = append(geoData, encodeField(2, 2, siteData)...)
          		}
           
          		allEntries = append(allEntries, encodeField(1, 2, geoData)...)
          		fmt.Printf("  ‚úÖ Added %d patterns\n", len(sites))
          		totalSites += len(sites)
          	}
           
          	if err := os.WriteFile(outputFile, allEntries, 0644); err != nil {
          		log.Fatalf("Failed to write output file: %v", err)
          	}
           
          	fmt.Printf("\nüéâ Generated %s\n", outputFile)
          	fmt.Printf("üìä Size: %d bytes\n", len(allEntries))
          	fmt.Printf("üìà Statistics:\n")
          	fmt.Printf("  Categories: %d\n", len(entries))
          	fmt.Printf("  Total patterns: %d\n", totalSites)
          	
          	for typ, count := range typeStats {
          		fmt.Printf("  %-10s: %d\n", typ, count)
          	}
          }
          EOF

      - name: Generate GeoSite Binary
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          echo "Generating geosite.dat binary file..."
          go run generate_geosite.go
          
          if [ ! -f "geosite.dat" ] || [ ! -s "geosite.dat" ]; then
            echo "‚ùå ERROR: geosite.dat was not generated or is empty!"
            exit 1
          fi
          
          echo "‚úÖ geosite.dat generated successfully"
          echo "üìè File size: $(wc -c < geosite.dat) bytes"

      - name: Generate Checksum
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          sha256sum geosite.dat > geosite.dat.sha256sum
          echo "SHA256 Checksum:"
          cat geosite.dat.sha256sum

      - name: Set Release Date and Stats
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          RELEASE_DATE=$(date +'%Y-%m-%d %H:%M')
          echo "RELEASE_DATE=${RELEASE_DATE}" >> $GITHUB_ENV
          
          cd geosite.dat/data
          TOTAL_FILES=$(find . -maxdepth 1 -type f ! -name ".*" | wc -l)
          TOTAL_LINES=0
          
          for file in *; do
            if [ -f "$file" ] && [ ! -d "$file" ]; then
              LINES=$(tail -n +2 "$file" | grep -v '^#' | grep -v '^$' | wc -l)
              TOTAL_LINES=$((TOTAL_LINES + LINES))
            fi
          done
          
          echo "STATS_FILES=${TOTAL_FILES}" >> $GITHUB_ENV
          echo "STATS_LINES=${TOTAL_LINES}" >> $GITHUB_ENV
          
          echo "üìä Found $TOTAL_FILES categories with $TOTAL_LINES total patterns"

      - name: Delete Old Release Tag
        run: |
          git fetch --tags 2>/dev/null || true
          git tag -d latest 2>/dev/null || true
          git push origin :refs/tags/latest 2>/dev/null || true

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: latest
          name: "GeoSite Build: $(date +'%Y-%m-%d %H:%M')"
          body: |
            ## üó∫Ô∏è GeoSite Data Build
            
            **–î–∞—Ç–∞ —Å–±–æ—Ä–∫–∏:** $(date +'%Y-%m-%d %H:%M')
            **–ö–∞—Ç–µ–≥–æ—Ä–∏–π:** ${{ env.STATS_FILES || 'N/A' }}
            **–í—Å–µ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:** ${{ env.STATS_LINES || 'N/A' }}
            
            ### üîí –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏:
            ```
            sha256sum: $(cat geosite.dat.sha256sum 2>/dev/null | cut -d' ' -f1 || echo 'N/A')
            ```
            
            ### üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
            –§–∞–π–ª—ã –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –≤ `geosite.dat/data/`:
            ```
            geosite.dat/data/
            ‚îú‚îÄ‚îÄ google      # –ö–∞—Ç–µ–≥–æ—Ä–∏—è "google"
            ‚îú‚îÄ‚îÄ category-ru # –ö–∞—Ç–µ–≥–æ—Ä–∏—è "category-ru"
            ‚îî‚îÄ‚îÄ telegram    # –ö–∞—Ç–µ–≥–æ—Ä–∏—è "telegram"
            ```
          draft: false
          prerelease: false
          make_latest: true
          files: |
            geosite.dat
            geosite.dat.sha256sum
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
