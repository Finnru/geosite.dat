name: Build-GeoSite-Dat

on:
  workflow_dispatch: # –¢–æ–ª—å–∫–æ —Ä—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.24'

      - name: Check for changes in geosite data
        id: check_changes
        run: |
          echo "Checking for changes in geosite data files..."
          
          # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
          mkdir -p geosite.dat/data
          
          # –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
          echo "Files in geosite.dat/data/:"
          ls -la geosite.dat/data/ 2>/dev/null || echo "No files found"
          
          # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ geosite.dat/data —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–æ–º–º–∏—Ç–∞
          if git diff --name-only HEAD~1 -- geosite.dat/data/ 2>/dev/null | grep -q .; then
            echo "Changes detected in geosite data files"
            echo "has_changes=true" >> $GITHUB_OUTPUT
          else
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ geosite.dat
            if [ -f "geosite.dat" ]; then
              echo "No changes in geosite data files, geosite.dat already exists"
              echo "has_changes=false" >> $GITHUB_OUTPUT
            else
              echo "No geosite.dat found, will generate"
              echo "has_changes=true" >> $GITHUB_OUTPUT
            fi
          fi

      - name: Validate GeoSite Files
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          echo "Validating geosite data files..."
          cd geosite.dat/data
          
          ERROR_COUNT=0
          FILE_COUNT=0
          
          for file in *; do
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞–ø–∫–∏ –∏ —Å–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã
            if [ -f "$file" ] && [ ! -d "$file" ]; then
              FILE_COUNT=$((FILE_COUNT + 1))
              echo "Validating $file..."
              
              # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
              if [ ! -s "$file" ]; then
                echo "‚ùå ERROR: $file is empty"
                ERROR_COUNT=$((ERROR_COUNT + 1))
                continue
              fi
              
              # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É - –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
              FIRST_LINE=$(head -1 "$file" | xargs)
              if [[ ! "$FIRST_LINE" =~ ^[a-zA-Z0-9_-]+:$ ]]; then
                echo "‚ùå ERROR: First line must be category name ending with ':'"
                echo "  Found: '$FIRST_LINE'"
                echo "  Expected format: 'category-name:'"
                ERROR_COUNT=$((ERROR_COUNT + 1))
              else
                CATEGORY_NAME="${FIRST_LINE%:}"
                echo "  Category: $CATEGORY_NAME"
              fi
              
              # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –∑–∞–ø–∏—Å–µ–π
              LINE_NUM=0
              while IFS= read -r line; do
                LINE_NUM=$((LINE_NUM + 1))
                line_clean=$(echo "$line" | sed 's/#.*//' | xargs)
                
                if [ -z "$line_clean" ] || [ "$LINE_NUM" -eq 1 ]; then
                  continue
                fi
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã Xray GeoSite
                if [[ "$line_clean" =~ ^(domain:|full:|regexp:|keyword:) ]]; then
                  # –ü—Ä–æ–≤–µ—Ä—è–µ–º keyword —Ñ–æ—Ä–º–∞—Ç
                  if [[ "$line_clean" =~ ^keyword: ]]; then
                    KEYWORD_VALUE="${line_clean#keyword:}"
                    if [[ "$KEYWORD_VALUE" =~ [*?\[\]{}()\\|] ]]; then
                      echo "‚ö†Ô∏è  WARNING: Line $LINE_NUM - keyword contains regex special chars: '$line_clean'"
                    fi
                  fi
                elif [[ "$line_clean" =~ ^@ ]]; then
                  echo "  Found reference: $line_clean"
                elif [[ "$line_clean" =~ ^[a-zA-Z0-9.*_-]+$ ]]; then
                  echo "  Found domain pattern: $line_clean"
                else
                  echo "‚ö†Ô∏è  WARNING: Line $LINE_NUM has unexpected format: '$line_clean'"
                fi
              done < "$file"
              
              echo "‚úÖ $file validation completed"
            fi
          done
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "‚ùå ERROR: No files found in geosite.dat/data/"
            ERROR_COUNT=$((ERROR_COUNT + 1))
          fi
          
          if [ $ERROR_COUNT -gt 0 ]; then
            echo "‚ùå Validation failed with $ERROR_COUNT error(s)"
            exit 1
          fi
          
          echo "‚úÖ All $FILE_COUNT geosite files validated successfully"

      - name: Create GeoSite Generator Script
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          echo "Creating geosite generator script for files without extension..."
          
          cat << 'EOF' > generate_geosite.go
          package main
          
          import (
          	"bufio"
          	"encoding/binary"
          	"fmt"
          	"log"
          	"os"
          	"path/filepath"
          	"sort"
          	"strings"
          )
          
          type Site struct {
          	Type  string
          	Value string
          	Attrs []string
          }
          
          func writeVarint(v uint32) []byte {
          	var buf [binary.MaxVarintLen32]byte
          	n := binary.PutUvarint(buf[:], uint64(v))
          	return buf[:n]
          }
          
          func encodeField(num int, wireType int, data []byte) []byte {
          	tag := uint32((num << 3) | wireType)
          	res := writeVarint(tag)
          	if wireType == 2 {
          		res = append(res, writeVarint(uint32(len(data)))...)
          	}
          	res = append(res, data...)
          	return res
          }
          
          func parseLine(line string, lineNum int, filename string) (string, *Site) {
          	line = strings.TrimSpace(line)
          	if line == "" || strings.HasPrefix(line, "#") {
          		return "", nil
          	}
          	
          	// –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "google:")
          	if lineNum == 0 && strings.HasSuffix(line, ":") {
          		return line, nil
          	}
          	
          	// –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω –∏ –∞—Ç—Ä–∏–±—É—Ç—ã
          	parts := strings.SplitN(line, " ", 2)
          	pattern := parts[0]
          	var attrs []string
          	
          	if len(parts) > 1 {
          		attrStr := parts[1]
          		attrParts := strings.Split(attrStr, " ")
          		for _, attr := range attrParts {
          			attr = strings.TrimSpace(attr)
          			if attr != "" && strings.HasPrefix(attr, "@") {
          				attrs = append(attrs, strings.TrimPrefix(attr, "@"))
          			}
          		}
          	}
          	
          	var patternType, patternValue string
           
          	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–∞—Ç—Ç–µ—Ä–Ω–∞
          	switch {
          	case strings.HasPrefix(pattern, "domain:"):
          		patternType = "domain"
          		patternValue = strings.TrimPrefix(pattern, "domain:")
          	case strings.HasPrefix(pattern, "regexp:"):
          		patternType = "regexp"
          		patternValue = strings.TrimPrefix(pattern, "regexp:")
          	case strings.HasPrefix(pattern, "full:"):
          		patternType = "full"
          		patternValue = strings.TrimPrefix(pattern, "full:")
          	case strings.HasPrefix(pattern, "keyword:"):
          		patternType = "keyword"
          		patternValue = strings.TrimPrefix(pattern, "keyword:")
          	case pattern == "@":
          		patternType = "reference"
          		patternValue = "@"
          	case strings.HasPrefix(pattern, "@"):
          		patternType = "reference"
          		patternValue = strings.TrimPrefix(pattern, "@")
          	default:
          		// –û–±—ã—á–Ω—ã–π –¥–æ–º–µ–Ω –∏–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω —Å wildcard
          		patternType = "domain"
          		patternValue = pattern
          	}
          	
          	return pattern, &Site{
          		Type:  patternType,
          		Value: patternValue,
          		Attrs: attrs,
          	}
          }
          
          func encodeSite(site *Site) []byte {
          	var data []byte
          	
          	// –¢–∏–ø –ø–∞—Ç—Ç–µ—Ä–Ω–∞
          	data = append(data, encodeField(1, 2, []byte(site.Type))...)
          	
          	// –ó–Ω–∞—á–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
          	data = append(data, encodeField(2, 2, []byte(site.Value))...)
          	
          	// –ê—Ç—Ä–∏–±—É—Ç—ã
          	for _, attr := range site.Attrs {
          		data = append(data, encodeField(3, 2, []byte(attr))...)
          	}
          	
          	return data
          }
          
          func main() {
          	dataDir := "geosite.dat/data"
          	outputFile := "geosite.dat"
           
          	// –ß–∏—Ç–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
          	entries, err := os.ReadDir(dataDir)
          	if err != nil {
          		log.Fatalf("Failed to read data directory: %v", err)
          	}
          	
          	var allEntries []byte
          	typeStats := make(map[string]int)
          	totalSites := 0
           
          	for _, entry := range entries {
          		// –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞–ø–∫–∏ –∏ —Ñ–∞–π–ª—ã —Å —Ç–æ—á–∫–æ–π –≤ –Ω–∞—á–∞–ª–µ
          		if entry.IsDir() || strings.HasPrefix(entry.Name(), ".") {
          			continue
          		}
           
          		// –ò–º—è —Ñ–∞–π–ª–∞ = –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "google")
          		categoryName := entry.Name()
          		fmt.Printf("üìÅ Processing category: %s\n", categoryName)
           
          		filePath := filepath.Join(dataDir, entry.Name())
          		file, err := os.Open(filePath)
          		if err != nil {
          			log.Printf("Warning: Failed to open %s: %v", filePath, err)
          			continue
          		}
           
          		var sites []*Site
          		scanner := bufio.NewScanner(file)
          		lineNum := 0
           
          		for scanner.Scan() {
          			pattern, site := parseLine(scanner.Text(), lineNum, categoryName)
          			lineNum++
                  
                  if site != nil && pattern != "" {
                    sites = append(sites, site)
                    typeStats[site.Type]++
                  }
          		}
           
          		file.Close()
           
          		if err := scanner.Err(); err != nil {
          			log.Printf("Warning: Error reading %s: %v", filePath, err)
          		}
           
          		// –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
          		sort.Slice(sites, func(i, j int) bool {
          			if sites[i].Type != sites[j].Type {
          				return sites[i].Type < sites[j].Type
          			}
          			return sites[i].Value < sites[j].Value
          		})
           
          		// –ö–æ–¥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
          		var geoData []byte
           
          		// –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–≥–µ–æ–∫–æ–¥)
          		geoData = append(geoData, encodeField(1, 2, []byte(categoryName))...)
           
          		// –°–∞–π—Ç—ã/–ø–∞—Ç—Ç–µ—Ä–Ω—ã
          		for _, site := range sites {
          			siteData := encodeSite(site)
          			geoData = append(geoData, encodeField(2, 2, siteData)...)
          		}
           
          		// –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
          		allEntries = append(allEntries, encodeField(1, 2, geoData)...)
           
          		fmt.Printf("  ‚úÖ Added %d sites/patterns\n", len(sites))
          		totalSites += len(sites)
          	}
           
          	// –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª
          	if err := os.WriteFile(outputFile, allEntries, 0644); err != nil {
          		log.Fatalf("Failed to write output file: %v", err)
          	}
           
          	fmt.Printf("\nüéâ Successfully generated %s\n", outputFile)
          	fmt.Printf("üìä Total size: %d bytes\n", len(allEntries))
          	fmt.Printf("üìà Statistics:\n")
          	fmt.Printf("  Total categories: %d\n", len(entries))
          	fmt.Printf("  Total patterns: %d\n", totalSites)
          	
          	for typ, count := range typeStats {
          		fmt.Printf("  %-10s: %d\n", typ, count)
          	}
          }
          EOF

      - name: Generate GeoSite Binary
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          echo "Generating geosite.dat binary file..."
          go run generate_geosite.go
          
          # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
          if [ ! -f "geosite.dat" ] || [ ! -s "geosite.dat" ]; then
            echo "‚ùå ERROR: geosite.dat was not generated or is empty!"
            exit 1
          fi
          
          echo "‚úÖ geosite.dat generated successfully"
          echo "üìè File size: $(wc -c < geosite.dat) bytes"

      - name: Generate Checksum
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          sha256sum geosite.dat > geosite.dat.sha256sum
          echo "SHA256 Checksum:"
          cat geosite.dat.sha256sum

      - name: Set Release Date and Stats
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          RELEASE_DATE=$(date +'%Y-%m-%d %H:%M')
          echo "RELEASE_DATE=${RELEASE_DATE}" >> $GITHUB_ENV
          
          # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
          cd geosite.dat/data
          TOTAL_FILES=$(find . -maxdepth 1 -type f ! -name ".*" | wc -l)
          TOTAL_LINES=0
          TOTAL_CATEGORIES=0
          
          for file in *; do
            if [ -f "$file" ] && [ ! -d "$file" ]; then
              TOTAL_CATEGORIES=$((TOTAL_CATEGORIES + 1))
              # –°—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –Ω–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –Ω–µ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É (–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
              LINES=$(tail -n +2 "$file" | grep -v '^#' | grep -v '^$' | wc -l)
              TOTAL_LINES=$((TOTAL_LINES + LINES))
            fi
          done
          
          echo "STATS_FILES=${TOTAL_FILES}" >> $GITHUB_ENV
          echo "STATS_CATEGORIES=${TOTAL_CATEGORIES}" >> $GITHUB_ENV
          echo "STATS_LINES=${TOTAL_LINES}" >> $GITHUB_ENV
          
          echo "üìä Statistics:"
          echo "  Files: $TOTAL_FILES"
          echo "  Categories: $TOTAL_CATEGORIES"
          echo "  Patterns: $TOTAL_LINES"

      - name: Skip Generation (No Changes)
        if: steps.check_changes.outputs.has_changes == 'false'
        run: |
          echo "‚è≠Ô∏è  No changes detected in geosite data files"
          echo "Skipping binary generation"
          echo "Using existing geosite.dat"

      - name: Delete Old Release Tag
        run: |
          # –£–¥–∞–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∏ —É–¥–∞–ª–µ–Ω–Ω—ã–π —Ç–µ–≥ latest
          git tag -d latest 2>/dev/null || true
          git push origin :refs/tags/latest 2>/dev/null || true

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: latest
          name: "GeoSite Build: $(date +'%Y-%m-%d %H:%M')"
          body: |
            ## üó∫Ô∏è GeoSite Data Build
            
            **–î–∞—Ç–∞ —Å–±–æ—Ä–∫–∏:** $(date +'%Y-%m-%d %H:%M')
            **–ö–∞—Ç–µ–≥–æ—Ä–∏–π:** ${{ env.STATS_CATEGORIES || 'N/A' }}
            **–í—Å–µ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:** ${{ env.STATS_LINES || 'N/A' }}
            
            ### üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤:
            –§–∞–π–ª—ã –≤ `geosite.dat/data/` (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è):
            ```
            geosite.dat/data/
            ‚îú‚îÄ‚îÄ google      # –ö–∞—Ç–µ–≥–æ—Ä–∏—è "google"
            ‚îú‚îÄ‚îÄ category-ru # –ö–∞—Ç–µ–≥–æ—Ä–∏—è "category-ru" 
            ‚îî‚îÄ‚îÄ telegram    # –ö–∞—Ç–µ–≥–æ—Ä–∏—è "telegram"
            ```
            
            ### üìù –§–æ—Ä–º–∞—Ç –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞:
            ```
            category-name:     # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            domain:example.com
            full:example.org
            keyword:tracking
            regexp:^https?://.*\.com/
            *.example.net
            @other-category
            ```
            
            ### ‚öôÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å Xray:
            ```json
            {
              "routing": {
                "rules": [
                  {
                    "type": "field",
                    "outboundTag": "proxy",
                    "domain": [
                      "geosite:google",
                      "geosite:telegram"
                    ]
                  }
                ]
              }
            }
            ```
            
            ### üîí –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏:
            ```
            sha256sum: $(cat geosite.dat.sha256sum 2>/dev/null | cut -d' ' -f1 || echo 'N/A')
            ```
            
            ### üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ:
            - –†–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ —Ñ–∞–π–ª—ã –≤ `geosite.dat/data/`
            - –ó–∞–ø—É—Å—Ç–∏—Ç–µ workflow –≤—Ä—É—á–Ω—É—é
            - –°–∫–∞—á–∞–π—Ç–µ –Ω–æ–≤—ã–π `geosite.dat` –∏–∑ —ç—Ç–æ–≥–æ —Ä–µ–ª–∏–∑–∞
          draft: false
          prerelease: false
          make_latest: true
          files: |
            geosite.dat
            geosite.dat.sha256sum
          generate_release_notes: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
